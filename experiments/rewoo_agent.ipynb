{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, TypedDict\n",
    "\n",
    "import sympy as sp\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini-2024-07-18', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[MessagesState]\n",
    "    task: str\n",
    "    plan_string: str\n",
    "    steps: List\n",
    "    results: Dict\n",
    "    result: str\n",
    "\n",
    "\n",
    "# Define a sympy-based tool\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate an arithmetic expression using sympy.\n",
    "\n",
    "    Args:\n",
    "        expression: arithmetic expression as a string (e.g., '3 + 4')\n",
    "\n",
    "    Returns:\n",
    "        The evaluated result as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expr = sp.sympify(expression)\n",
    "        evaluated = expr.evalf() if expr.is_number else expr\n",
    "        return str(evaluated)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Define a LLM tool\n",
    "@tool\n",
    "def llm_tool(expression: str) -> str:\n",
    "    \"\"\"Use LLM like yourself to process the input string.\n",
    "    This is useful for tasks that require reasoning or understanding of the context.\n",
    "    For example, you can use it to provide explanations.\n",
    "\n",
    "    Args:\n",
    "        expression: input string to be processed by LLM\n",
    "\n",
    "    Returns:\n",
    "        The processed output as a string.\n",
    "    \"\"\"\n",
    "    response = llm.invoke([SystemMessage(content=expression)])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# Augment the LLM with the sympy tool\n",
    "tools = [calculate, llm_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planer_prompt_system = \"\"\"\n",
    "### INSTRUCTIONS ###\n",
    "You are a math problem solving planner. For the following task, make plans that can solve \\\n",
    "the problem step by step. For each plan, indicate which external tool together with tool input to retrieve \\\n",
    "evidence. You can store the evidence into a variable #E that can be called by later tools \\\n",
    "(Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) Calculate[input]: A tool that is used for solving math expressions using sympy.\n",
    "(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general world knowledge and \\\n",
    "common sense. Prioritize it when you are confident in solving the problem yourself. Input can be any instruction.\n",
    "\n",
    "# FIXME:\n",
    "### EXAMPLE ###\n",
    "Task: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\n",
    "hours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\n",
    "less than Toby. How many hours did Rebecca work?\n",
    "\n",
    "Plan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\n",
    "with Wolfram Alpha.\n",
    "\n",
    "#E1 = WolframAlpha[Solve x + (2x − 10) + ((2x − 10) − 8) = 157]\n",
    "Plan: Find out the number of hours Thomas worked.\n",
    "#E2 = llm_tool[What is x, given #E1]\n",
    "\n",
    "Plan: Calculate the number of hours Rebecca worked.\n",
    "#E3 = Calculator[(2 ∗ #E2 − 10) − 8]\n",
    "\"\"\"\n",
    "\n",
    "planer_prompt_human = \"\"\"\n",
    "### YOUR TASK ###\n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}\n",
    "Plan:\n",
    "\"\"\"\n",
    "\n",
    "planer_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", planer_prompt_system),\n",
    "        (\"user\", planer_prompt_human)\n",
    "    ]\n",
    ")\n",
    "\n",
    "solver_prompt = \"\"\"\n",
    "### INSTRUCTIONS ###\n",
    "Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \\\n",
    "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\n",
    "contain irrelevant information.\n",
    "\n",
    "Respond with the answer in a format: \"Answer: <value>\". Value should be a number without \\\n",
    "any units. If you are not sure about the answer, respond with \"I don't know\".\n",
    "\n",
    "### TASK ###\n",
    "{task}\n",
    "\n",
    "### PLAN ###\n",
    "{plan}\n",
    "\n",
    "### ANSWER ###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner node\n",
    "def planner(state: AgentState):\n",
    "    \"\"\"Generate a step-by-step plan to solve the problem\"\"\"\n",
    "    regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "\n",
    "    task = state[\"task\"]\n",
    "\n",
    "    prompt = planer_prompt_template.format_messages(task=task)\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Extract the plan string from the response\n",
    "    matches = re.findall(regex_pattern, response.content)\n",
    "    return {\"steps\": matches, \"plan_string\": response.content, \"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "def _get_current_task(state: AgentState):\n",
    "    if \"results\" not in state or state[\"results\"] is None:\n",
    "        return 1\n",
    "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "        return None\n",
    "    else:\n",
    "        return len(state[\"results\"]) + 1\n",
    "\n",
    "# Executor node\n",
    "def executor(state: AgentState):\n",
    "    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n",
    "    _step = _get_current_task(state)\n",
    "    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n",
    "    _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "    for k, v in _results.items():\n",
    "        tool_input = tool_input.replace(k, v)\n",
    "    if tool == \"Calculate\":\n",
    "        result = calculate.invoke(tool_input)\n",
    "    elif tool == \"LLM\":\n",
    "        result = llm_tool.invoke(tool_input)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    _results[step_name] = str(result)\n",
    "\n",
    "    tool_message = ToolMessage(content=f\"{tool_input}\\nResult: {result}\", artifact=result, tool_call_id=step_name)\n",
    "\n",
    "    return {\"results\": _results, \"messages\": state[\"messages\"] + [tool_message]}\n",
    "\n",
    "def solve(state: AgentState):\n",
    "    plan = \"\"\n",
    "    for _plan, step_name, tool, tool_input in state[\"steps\"]:\n",
    "        _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "        for k, v in _results.items():\n",
    "            tool_input = tool_input.replace(k, v)\n",
    "            step_name = step_name.replace(k, v)\n",
    "        plan += f\"Plan: {_plan}\\n{step_name} = {tool}[{tool_input}]\"\n",
    "    prompt = solver_prompt.format(plan=plan, task=state[\"task\"])\n",
    "    result = llm.invoke(prompt)\n",
    "    return {\"result\": result.content, \"messages\": state[\"messages\"] + [result]}\n",
    "\n",
    "def _route(state: AgentState):\n",
    "    _step = _get_current_task(state)\n",
    "    if _step is None:\n",
    "        # We have executed all tasks\n",
    "        return \"solve\"\n",
    "    else:\n",
    "        # We are still executing tasks, loop back to the \"tool\" node\n",
    "        return \"tool\"\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"plan\", planner)\n",
    "graph.add_node(\"tool\", executor)\n",
    "graph.add_node(\"solve\", solve)\n",
    "\n",
    "graph.add_edge(\"plan\", \"tool\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "graph.add_conditional_edges(\"tool\", _route)\n",
    "graph.add_edge(START, \"plan\")\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "\n",
    "task = \"James has a $1000 budget. He spends 30% on food, \\\n",
    "15% on accommodation, 25% on entertainment. \\\n",
    "How much does he spend on coursework materials?\"\n",
    "\n",
    "messages = [HumanMessage(content=task)]\n",
    "\n",
    "result = agent.invoke({\"task\": task, \"messages\": messages})\n",
    "\n",
    "\n",
    "# # Print full conversation with steps\n",
    "# for m in agent.stream({\"task\": task, \"messages\": messages}):\n",
    "#     print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "James has a $1000 budget. He spends 30% on food, 15% on accommodation, 25% on entertainment. How much does he spend on coursework materials?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Plan: First, calculate the total amount James spends on food, accommodation, and entertainment based on his $1000 budget. This will involve calculating 30% of $1000 for food, 15% for accommodation, and 25% for entertainment. I will use the Calculate tool to perform these calculations. \n",
      "#E1 = Calculate[0.30 * 1000 + 0.15 * 1000 + 0.25 * 1000]\n",
      "\n",
      "Plan: Next, determine the total amount spent on food, accommodation, and entertainment by retrieving the result from #E1. Then, subtract this total from the initial budget of $1000 to find out how much is left for coursework materials. I will use the Calculate tool for this subtraction.\n",
      "#E2 = Calculate[1000 - #E1]\n",
      "\n",
      "Plan: Finally, I will summarize the amount James spends on coursework materials based on the calculation from #E2. I will use the LLM tool to provide a clear explanation of the result.\n",
      "#E3 = LLM[How much does James spend on coursework materials given #E2]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "0.30 * 1000 + 0.15 * 1000 + 0.25 * 1000\n",
      "Result: 700.000000000000\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "1000 - 700.000000000000\n",
      "Result: 300.000000000000\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "How much does James spend on coursework materials given 300.000000000000\n",
      "Result: It seems like you provided a number (300.000000000000) but didn't specify what it refers to in terms of coursework materials. If you could provide more context or details about the costs or the specific items James is purchasing, I would be happy to help you calculate or analyze his spending on coursework materials!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 300\n"
     ]
    }
   ],
   "source": [
    "# Print full conversation with steps\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
