{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import re\n",
    "from typing import Dict, List, TypedDict\n",
    "\n",
    "import sympy as sp\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini-2024-07-18', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: List[MessagesState]\n",
    "    task: str\n",
    "    plan_string: str\n",
    "    steps: List\n",
    "    results: Dict\n",
    "    result: str\n",
    "\n",
    "\n",
    "# Define a sympy-based tool\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate an arithmetic expression using sympy.\n",
    "\n",
    "    Args:\n",
    "        expression: arithmetic expression as a string (e.g., '3 + 4')\n",
    "\n",
    "    Returns:\n",
    "        The evaluated result as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expr = sp.sympify(expression)\n",
    "        evaluated = expr.evalf() if expr.is_number else expr\n",
    "        return str(evaluated)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Define a LLM tool\n",
    "@tool\n",
    "def llm_tool(expression: str) -> str:\n",
    "    \"\"\"Use LLM like yourself to process the input string.\n",
    "    This is useful for tasks that require reasoning or understanding of the context.\n",
    "    For example, you can use it to provide explanations.\n",
    "\n",
    "    Args:\n",
    "        expression: input string to be processed by LLM\n",
    "\n",
    "    Returns:\n",
    "        The processed output as a string.\n",
    "    \"\"\"\n",
    "    response = llm.invoke([SystemMessage(content=expression)])\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# Augment the LLM with the sympy tool\n",
    "tools = [calculate, llm_tool]\n",
    "tools_by_name = {tool.name: tool for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "planer_prompt_system = \"\"\"\n",
    "### INSTRUCTIONS ###\n",
    "You are a math problem solving planner. For the following task, make plans that can solve \\\n",
    "the problem step by step. For each plan, indicate which external tool together with tool input to retrieve \\\n",
    "evidence. You can store the evidence into a variable #E that can be called by later tools \\\n",
    "(Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) Calculate[input]: A tool that is used for solving math expressions using sympy.\n",
    "(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general world knowledge and \\\n",
    "common sense. Prioritize it when you are confident in solving the problem yourself. Input can be any instruction.\n",
    "\n",
    "### EXAMPLE ###\n",
    "Task: A person has $500. They spend 40% on groceries, 20% on utilities, and 10% on transportation. \\\n",
    "How much money do they have left?\n",
    "\n",
    "Plan: Calculate the total amount spent on groceries, utilities, and transportation.\n",
    "#E1 = Calculate[0.40 * 500 + 0.20 * 500 + 0.10 * 500]\n",
    "\n",
    "Plan: Subtract the total amount spent from the initial amount to find the remaining money.\n",
    "#E2 = Calculate[500 - #E1]\n",
    "\"\"\"\n",
    "\n",
    "planer_prompt_human = \"\"\"\n",
    "### YOUR TASK ###\n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}\n",
    "Plan:\n",
    "\"\"\"\n",
    "\n",
    "planer_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", planer_prompt_system),\n",
    "        (\"user\", planer_prompt_human)\n",
    "    ]\n",
    ")\n",
    "\n",
    "solver_prompt = \"\"\"\n",
    "### INSTRUCTIONS ###\n",
    "Solve the following task or problem. To solve the problem, we have made step-by-step Plan and \\\n",
    "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\n",
    "contain irrelevant information.\n",
    "\n",
    "Respond with the answer in a format: \"Answer: <value>\". Value should be a number without \\\n",
    "any units. If you are not sure about the answer, respond with \"I don't know\".\n",
    "\n",
    "### TASK ###\n",
    "{task}\n",
    "\n",
    "### PLAN ###\n",
    "{plan}\n",
    "\n",
    "### ANSWER ###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reflection node returned END\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "James has a $1000 budget. He spends 30% on food, 15% on accommodation, 25% on entertainment. How much does he spend on coursework materials?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Plan: First, I will calculate the total amount James spends on food, accommodation, and entertainment by determining the percentages of his $1000 budget allocated to each category. This will involve calculating 30% for food, 15% for accommodation, and 25% for entertainment. I will sum these amounts to find the total expenditure on these categories. \n",
      "#E1 = Calculate[0.30 * 1000 + 0.15 * 1000 + 0.25 * 1000]\n",
      "\n",
      "Plan: Next, I will subtract the total amount spent on food, accommodation, and entertainment from James's initial budget of $1000 to find out how much he has left for coursework materials. \n",
      "#E2 = Calculate[1000 - #E1]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "0.30 * 1000 + 0.15 * 1000 + 0.25 * 1000\n",
      "Result: 700.000000000000\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "1000 - 700.000000000000\n",
      "Result: 300.000000000000\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Answer: 300\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "END\n"
     ]
    }
   ],
   "source": [
    "# Planner node\n",
    "def planner(state: AgentState):\n",
    "    \"\"\"Generate a step-by-step plan to solve the problem\"\"\"\n",
    "    regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "\n",
    "    task = state[\"task\"]\n",
    "\n",
    "    prompt = planer_prompt_template.format_messages(task=task)\n",
    "    response = llm.invoke(state['messages'] + prompt)\n",
    "\n",
    "    # Extract the plan string from the response\n",
    "    matches = re.findall(regex_pattern, response.content)\n",
    "    return {\"steps\": matches, \"plan_string\": response.content, \"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "def _get_current_task(state: AgentState):\n",
    "    if \"results\" not in state or state[\"results\"] is None:\n",
    "        return 1\n",
    "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "        return None\n",
    "    else:\n",
    "        return len(state[\"results\"]) + 1\n",
    "\n",
    "# Executor node\n",
    "def executor(state: AgentState):\n",
    "    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n",
    "    _step = _get_current_task(state)\n",
    "    _, step_name, tool_name, tool_input = state[\"steps\"][_step - 1]\n",
    "    _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "    for k, v in _results.items():\n",
    "        tool_input = tool_input.replace(k, v)\n",
    "    if tool_name == \"Calculate\":\n",
    "        result = calculate.invoke(tool_input)\n",
    "    elif tool_name == \"LLM\":\n",
    "        result = llm_tool.invoke(tool_input)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    _results[step_name] = str(result)\n",
    "\n",
    "    tool_message = ToolMessage(content=f\"{tool_input}\\nResult: {result}\", artifact=result, tool_call_id=step_name)\n",
    "\n",
    "    return {\"results\": _results, \"messages\": state[\"messages\"] + [tool_message]}\n",
    "\n",
    "def solve(state: AgentState):\n",
    "    plan = \"\"\n",
    "    for _plan, step_name, tool_name, tool_input in state[\"steps\"]:\n",
    "        _results = (state[\"results\"] or {}) if \"results\" in state else {}\n",
    "        for k, v in _results.items():\n",
    "            tool_input = tool_input.replace(k, v)\n",
    "            step_name = step_name.replace(k, v)\n",
    "        plan += f\"Plan: {_plan}\\n{step_name} = {tool_name}[{tool_input}]\"\n",
    "    prompt = solver_prompt.format(plan=plan, task=state[\"task\"])\n",
    "    result = llm.invoke(prompt)\n",
    "    return {\"result\": result.content, \"messages\": state[\"messages\"] + [result]}\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a teacher grading a math problems solution.\"\n",
    "            \" Generate critique and recommendations for the user's solution path.\"\n",
    "            \" Make sure to be specific and provide detailed feedback.\"\n",
    "            \" Do not refer to the solultion clarification or style, just focus on the solution path.\"\n",
    "            \" If the solution is correct, just say 'END' with upper case.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def reflection_node(state: AgentState) -> AgentState:\n",
    "    # Other messages we need to adjust\n",
    "    cls_map = {\"ai\": HumanMessage, \"human\": AIMessage, \"tool\": AIMessage}\n",
    "    # First message is the original user request. We hold it the same for all nodes\n",
    "    translated = [state[\"messages\"][0]] + [\n",
    "        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]\n",
    "    ]\n",
    "    res = llm.invoke(\n",
    "        reflection_prompt.format_messages(messages=translated),\n",
    "        stop=[\"\\n\\n###\"],\n",
    "    )\n",
    "\n",
    "    if res.content.lower == \"correct\":\n",
    "        # If the solution is correct, we can stop\n",
    "        return {\"messages\": [HumanMessage(content=res.content)]}\n",
    "\n",
    "    # We treat the output of this as human feedback for the generator\n",
    "    return {\"messages\": state[\"messages\"] + [HumanMessage(content=res.content)]}\n",
    "\n",
    "\n",
    "def _route(state: AgentState):\n",
    "    _step = _get_current_task(state)\n",
    "    if _step is None:\n",
    "        # We have executed all tasks\n",
    "        return \"solve\"\n",
    "    else:\n",
    "        # We are still executing tasks, loop back to the \"tool\" node\n",
    "        return \"tool\"\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    if len([msg for msg in state[\"messages\"] if isinstance(msg, AIMessage)]) > 6:\n",
    "        print(\"Reached the limit of messages\")\n",
    "        return END\n",
    "\n",
    "    if \"END\" in state[\"messages\"][-1].content:\n",
    "        # If the last message is \"END\", we stop\n",
    "        print(\"Reflection node returned END\")\n",
    "        return END\n",
    "\n",
    "    return \"plan\"\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"plan\", planner)\n",
    "graph.add_node(\"tool\", executor)\n",
    "graph.add_node(\"solve\", solve)\n",
    "graph.add_node(\"reflect\", reflection_node)\n",
    "\n",
    "graph.add_edge(START, \"plan\")\n",
    "graph.add_edge(\"plan\", \"tool\")\n",
    "graph.add_conditional_edges(\"tool\", _route)\n",
    "graph.add_edge(\"solve\", \"reflect\")\n",
    "graph.add_conditional_edges(\"reflect\", should_continue)\n",
    "\n",
    "\n",
    "\n",
    "agent = graph.compile()\n",
    "\n",
    "\n",
    "task = \"James has a $1000 budget. He spends 30% on food, \\\n",
    "15% on accommodation, 25% on entertainment. \\\n",
    "How much does he spend on coursework materials?\"\n",
    "\n",
    "messages = [HumanMessage(content=task)]\n",
    "\n",
    "# # Print full conversation with steps\n",
    "# for m in agent.stream({\"task\": task, \"messages\": messages, \"should_continue\": True}):\n",
    "#     print(m)\n",
    "\n",
    "result = agent.invoke({\"task\": task, \"messages\": messages})\n",
    "\n",
    "# Print full conversation with steps\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
