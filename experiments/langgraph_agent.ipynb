{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Calculate 3 + 4.' additional_kwargs={} response_metadata={} id='1272e57c-0bf0-4c57-9f66-adba569bef46'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_g9B04LAqzQsrzuloXaHbAJR1', 'function': {'arguments': '{\"expression\":\"3 + 4\"}', 'name': 'calculate'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 105, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e5464522-553b-428c-acef-cd031de6e9b4-0' tool_calls=[{'name': 'calculate', 'args': {'expression': '3 + 4'}, 'id': 'call_g9B04LAqzQsrzuloXaHbAJR1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 105, 'output_tokens': 17, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='7.00000000000000' id='d5fa9d36-26f3-4da9-90b8-de26b1ed9a62' tool_call_id='call_g9B04LAqzQsrzuloXaHbAJR1'\n",
      "content='The result of \\\\( 3 + 4 \\\\) is \\\\( 7 \\\\).' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 135, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'finish_reason': 'stop', 'logprobs': None} id='run-f9fded57-57e7-46a5-932d-f2c5b0c899a8-0' usage_metadata={'input_tokens': 135, 'output_tokens': 19, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from typing import Literal\n",
    "import sympy as sp\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini-2024-07-18', temperature=0)\n",
    "\n",
    "# Define a single sympy-based tool\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate an arithmetic expression using sympy.\n",
    "\n",
    "    Args:\n",
    "        expression: arithmetic expression as a string (e.g., '3 + 4')\n",
    "\n",
    "    Returns:\n",
    "        The evaluated result as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expr = sp.sympify(expression)\n",
    "        evaluated = expr.evalf() if expr.is_number else expr\n",
    "        return str(evaluated)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Augment the LLM with the sympy tool\n",
    "tools = [calculate]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call the calculate tool\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic using sympy. When appropriate, output a tool call with an arithmetic expression.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the sympy tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"environment\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # Name returned by should_continue : Name of next node to visit\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "# display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke with an example arithmetic query using sympy\n",
    "messages = [HumanMessage(content=\"Calculate 3 + 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
