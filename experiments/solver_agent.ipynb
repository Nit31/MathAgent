{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 300\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from typing import Literal\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import re\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini-2024-07-18', temperature=0)\n",
    "\n",
    "# Define a single sympy-based tool\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Calculate an arithmetic expression using sympy.\n",
    "\n",
    "    Args:\n",
    "        expression: arithmetic expression as a string (e.g., '3 + 4')\n",
    "\n",
    "    Returns:\n",
    "        The evaluated result as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        expr = sp.sympify(expression)\n",
    "        evaluated = expr.evalf() if expr.is_number else expr\n",
    "        return str(evaluated)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "\n",
    "@tool\n",
    "def format_answer(text: str) -> str:\n",
    "    \"\"\"Returns only the numerical result (no text).\"\"\"\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", text)\n",
    "    if numbers:\n",
    "        return numbers[-1].split('.')[0] if numbers[-1].endswith('.0') else numbers[-1]\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# Augment the LLM with the sympy tool\n",
    "tools = [calculate, format_answer]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call the calculate tool\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a math problem solver. Follow these steps:\\n\"\n",
    "                                \"1. Use calculate tool for math operations\\n\"\n",
    "                                \"2. Use format_answer to present final results\\n\"\n",
    "                                \"3. Always return answers in 'Answer: number' format\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the sympy tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"environment\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    {\n",
    "        # Name returned by should_continue : Name of next node to visit\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "# display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke with an example arithmetic query using sympy\n",
    "# messages = [HumanMessage(content=\"James is a first-year student at a University in Chicago. He has a budget of $1000 per semester. He spends 30% of his money on food, 15% on accommodation, 25% on entertainment, and the rest on coursework materials. How much money does he spend on coursework materials?\")]\n",
    "# messages = agent.invoke({\"messages\": messages})\n",
    "# # for m in messages[\"messages\"]:\n",
    "# #     print(m)\n",
    "\n",
    "\n",
    "# final_answer = None\n",
    "\n",
    "# for m in reversed(messages[\"messages\"]):\n",
    "#     if hasattr(m, 'content') and m.content and re.search(r'\\d+', m.content):\n",
    "#         final_answer = m.content\n",
    "#         break\n",
    "\n",
    "# print(final_answer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "test_dataset = dataset[\"test\"]\n",
    "val_sample = test_dataset.shuffle(seed=42).select(range(100))\n",
    "\n",
    "def check_answer(model_answer, true_answer):\n",
    "    try:\n",
    "        true_answer = true_answer.split(',')\n",
    "        \n",
    "        true_answer = [int(x) for x in true_answer]\n",
    "    except Exception:\n",
    "        true_answer = [int(true_answer)]\n",
    "    \n",
    "    return int(model_answer) in true_answer\n",
    "\n",
    "k = 0\n",
    "model_answers = []\n",
    "\n",
    "for problem in tqdm(val_sample):\n",
    "    # Get the math problem and the correct answer\n",
    "    math_problem = problem['question']\n",
    "    correct_answer = problem['answer'].split(\"### \")[1]\n",
    "\n",
    "    # Generate the model's response using your agent\n",
    "    state = agent.invoke({\"messages\": [HumanMessage(content=math_problem)]})\n",
    "    model_response = state[\"messages\"][-1]  # Get final response\n",
    "    model_answers.append(model_response.content)\n",
    "\n",
    "    # Use regex to parse the numerical answer exactly as before\n",
    "    try:\n",
    "        model_ans = re.search(r'Answer:\\s*[^0-9]*([\\d]+(?:\\.\\d+)?)', model_response.content).group(1).strip()\n",
    "        k += 1 if check_answer(model_ans, correct_answer) else 0\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "print(f\"Precision: {k/len(val_sample)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
